# Image Description Toolkit

An AI-powered toolkit for generating descriptive text from images using local language models via Ollama. The toolkit provides a unified workflow system that orchestrates the entire pipeline from video frame extraction through HTML report generation, making it simple to process large collections of media files.

## ğŸŒŸ Features

- **ğŸ”„ Unified Workflow System**: Complete pipeline from video â†’ frames â†’ images â†’ descriptions â†’ HTML reports
- **ğŸ¤– AI-Powered Descriptions**: Generate natural language descriptions using local Ollama models
- **ğŸ¥ Video Frame Extraction**: Extract frames from videos for analysis
- **ğŸ–¼ï¸ Image Format Conversion**: Convert HEIC images to JPG automatically
- **ğŸ“„ HTML Report Generation**: Create beautiful web galleries with descriptions
- **âš¡ Batch Processing**: Handle multiple files and directories efficiently
- **ğŸ“Š Comprehensive Logging**: Professional logging with statistics and progress tracking
- **ğŸ› ï¸ Individual Script Access**: Use components separately when needed

## ğŸ”§ System Requirements

**Ollama is required for vision model inference and must be installed and running for the toolkit to function.**

### Install Ollama

**macOS/Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**Windows:**
Download and install from [https://ollama.ai/download/windows](https://ollama.ai/download/windows)

### Start Ollama Server

```bash
ollama serve
```

### Verify Ollama is Running

```bash
curl http://localhost:11434/api/version
```

If Ollama is running properly, you should see a JSON response with version information.

**âš ï¸ Important**: The Image Description Toolkit will not function unless Ollama is installed and running. Make sure to start the Ollama server before using any of the toolkit's AI-powered features.

## ğŸ“ Project Structure

```
Image-Description-Toolkit/
â”œâ”€â”€ workflow.py                # ğŸ¯ Main entry point - workflow wrapper
â”œâ”€â”€ scripts/                   # ğŸ”§ Core processing scripts
â”‚   â”œâ”€â”€ workflow.py           #    Workflow orchestrator (main engine)
â”‚   â”œâ”€â”€ video_frame_extractor.py #    Extract frames from videos
â”‚   â”œâ”€â”€ ConvertImage.py       #    Convert HEIC to JPG
â”‚   â”œâ”€â”€ image_describer.py    #    AI image description
â”‚   â”œâ”€â”€ descriptions_to_html.py #    Generate HTML reports
â”‚   â”œâ”€â”€ workflow_utils.py     #    Workflow utilities
â”‚   â”œâ”€â”€ workflow_config.json  #    Workflow configuration
â”‚   â”œâ”€â”€ image_describer_config.json # AI model settings
â”‚   â””â”€â”€ video_frame_extractor_config.json # Video processing config
â”œâ”€â”€ docs/                     # ğŸ“š Documentation
â”œâ”€â”€ tests/                    # ğŸ§ª Test suite and test files
â”œâ”€â”€ requirements.txt          # ğŸ“¦ Python dependencies
â”œâ”€â”€ .gitignore               # ğŸš« Git ignore rules
â””â”€â”€ README.md                # ğŸ“– This file
```

## ğŸš€ Quick Start

### Primary Usage (Recommended)

The **workflow system** is the main way to use this toolkit:

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Install Ollama and a vision model
# Download from https://ollama.ai/
ollama pull llava:7b  # or llama3.2-vision:11b, moondream, etc.

# 3. Process your media files (videos + images)
python workflow.py path/to/your/media

# 4. Find results in timestamped output directory
# -> workflow_output_YYYYMMDD_HHMMSS/
```

### Workflow Steps

The workflow automatically handles:
1. **Video Processing** â†’ Extract frames from MP4, MOV, AVI files  
2. **Image Conversion** â†’ Convert HEIC to JPG  
3. **AI Description** â†’ Generate descriptions using Ollama models  
4. **HTML Generation** â†’ Create beautiful web gallery with descriptions

### Advanced Workflow Usage

```bash
# Process only specific steps
python workflow.py media/ --steps describe,html

# Use custom output directory
python workflow.py media/ --output-dir my_results

# Override AI model
python workflow.py media/ --model llama3.2-vision:11b

# Dry run (see what would be processed)
python workflow.py media/ --dry-run

# Verbose logging
python workflow.py media/ --verbose
```

### Individual Script Usage (Advanced)

When you need fine-grained control, you can use scripts directly:

```bash
# Video frame extraction
cd scripts
python video_frame_extractor.py path/to/videos

# Image format conversion  
python ConvertImage.py path/to/heic/files --output converted/

# AI image descriptions
python image_describer.py path/to/images --model llava:7b

# HTML report generation
python descriptions_to_html.py descriptions.txt report.html
```

## ğŸ§ª Testing

```bash
# Run test suite
cd tests
python run_tests.py

# Test individual components
python test_workflow.py
```

## ğŸ› ï¸ Core Components

### Workflow System (`workflow.py` â†’ `scripts/workflow.py`)
The main orchestrator that provides a unified processing pipeline:
- **ğŸ¯ Simple Entry Point**: Just run `python workflow.py media_folder`
- **ğŸ”„ Complete Pipeline**: Handles videoâ†’framesâ†’conversionâ†’descriptionsâ†’HTML
- **ğŸ“Š Progress Tracking**: Real-time logging with comprehensive statistics  
- **ğŸ›¡ï¸ Error Resilience**: Continues processing despite individual file failures
- **âš™ï¸ Flexible Configuration**: Support for custom models, output directories, and step selection
- **ğŸ“‹ Professional Logging**: Timestamped logs with detailed statistics and summaries

### Video Frame Extractor (`scripts/video_frame_extractor.py`)
Extract frames from videos for image analysis:
- **ğŸ¬ Multiple Formats**: MP4, MOV, AVI, MKV support
- **â±ï¸ Flexible Extraction**: Time-based intervals (e.g., every 5 seconds)
- **ğŸ–¼ï¸ Quality Control**: Configurable resolution and image quality
- **ğŸ“ Organized Output**: Systematic frame numbering and folder structure

### Image Converter (`scripts/ConvertImage.py`)  
Convert HEIC images to JPG for broader compatibility:
- **ğŸ“± HEIC/HEIF Support**: Handle iPhone/iOS photos seamlessly
- **ğŸ”§ Quality Controls**: Configurable compression settings  
- **ğŸ“‹ Metadata Preservation**: Maintains EXIF data during conversion
- **âš¡ Batch Processing**: Convert entire directories efficiently

### AI Image Describer (`scripts/image_describer.py`)
Generate natural language descriptions using local Ollama models:
- **ğŸ¤– Multiple Models**: llava:7b, llama3.2-vision:11b, moondream, bakllava
- **ğŸ’¬ Custom Prompts**: Configurable description styles (detailed, brief, technical)
- **ğŸ  Local Processing**: No cloud dependencies, complete privacy
- **ğŸ“Š EXIF Integration**: Include camera settings, GPS, timestamps in output
- **ğŸ§  Memory Optimization**: Smart processing for large image collections

### HTML Report Generator (`scripts/descriptions_to_html.py`)
Create beautiful web galleries from descriptions:
- **ğŸŒ Responsive Design**: Mobile-friendly layouts
- **ğŸ¨ Professional Styling**: Clean, modern web interface
- **ğŸ” Interactive Features**: Easy browsing and navigation

## âš™ï¸ Configuration

Configuration files are located in the `scripts/` directory:

- **`scripts/workflow_config.json`** - Main workflow settings, step configuration, and output preferences
- **`scripts/image_describer_config.json`** - AI model selection, prompts, and processing parameters  
- **`scripts/video_frame_extractor_config.json`** - Video processing settings and frame extraction options

### Example Workflow Configuration

```json
{
  "workflow": {
    "default_steps": ["video", "convert", "describe", "html"],
    "steps": {
      "video_extraction": {
        "config_file": "video_frame_extractor_config.json"
      },
      "image_conversion": {
        "quality": 95,
        "keep_metadata": true
      },
      "image_description": {
        "model": "llava:7b",
        "prompt_style": "detailed",
        "config_file": "image_describer_config.json"
      },
      "html_generation": {
        "title": "Image Analysis Report",
        "include_details": false
      }
    }
  }
}
```

## ğŸ”§ Advanced Usage

### Workflow Examples

```bash
# Process entire media collection (videos + images)
python workflow.py /path/to/media/collection

# Only generate descriptions and HTML (skip video/conversion)
python workflow.py /path/to/images --steps describe,html

# Use different AI model
python workflow.py /path/to/images --model llama3.2-vision:11b

# Custom output location
python workflow.py /path/to/images --output-dir /custom/output/path

# Preview what will be processed
python workflow.py /path/to/images --dry-run

# Get detailed logging
python workflow.py /path/to/images --verbose
```

### Custom AI Models

```bash
# Install additional Ollama models
ollama pull llama3.2-vision:11b  # Larger, more capable model
ollama pull moondream:latest     # Lightweight alternative
ollama pull bakllava:latest      # Another vision model option

# Update scripts/image_describer_config.json to use your preferred model
```

### Output Structure

When you run the workflow, it creates a timestamped output directory:

```
workflow_output_20250721_143022/
â”œâ”€â”€ logs/                     # Detailed processing logs
â”‚   â”œâ”€â”€ workflow_orchestrator_20250721_143022.log
â”‚   â”œâ”€â”€ video_frame_extractor_20250721_143023.log
â”‚   â”œâ”€â”€ image_converter_20250721_143024.log
â”‚   â””â”€â”€ image_describer_20250721_143025.log
â”œâ”€â”€ extracted_frames/         # Video frames (if processing videos)
â”œâ”€â”€ converted_images/         # HEICâ†’JPG conversions (if needed)
â”œâ”€â”€ descriptions/            # AI-generated descriptions
â”‚   â””â”€â”€ image_descriptions.txt
â””â”€â”€ reports/                 # HTML reports
    â””â”€â”€ image_descriptions.html
```

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Install development dependencies**: `pip install -r requirements.txt`
4. **Test your setup**: `cd tests && python run_tests.py`
5. **Make your changes**
6. **Test the workflow**: `python workflow.py tests/test_files/ --dry-run`
7. **Update documentation** if needed
8. **Submit a pull request**

### Development Guidelines
- Follow PEP 8 style guidelines
- Add tests for new functionality  
- Ensure the workflow system continues to work end-to-end
- Update documentation for new features
- Test with multiple Python versions (3.8+)

## ğŸ“ Support & Documentation

- **ï¿½ Documentation**: Detailed guides available in the `docs/` directory
- **ğŸ› Issues**: Report bugs or request features via [GitHub Issues](https://github.com/kellylford/Image-Description-Toolkit/issues)
- **ï¿½ Discussions**: Join conversations in [GitHub Discussions](https://github.com/kellylford/Image-Description-Toolkit/discussions)
- **ğŸ§ª Testing**: Run `cd tests && python run_tests.py` to verify your setup

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ï¿½ **Ready to Get Started?**

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Install Ollama and pull a vision model  
ollama pull llava:7b

# 3. Test your setup
cd tests && python run_tests.py

# 4. Process your first media collection
python workflow.py path/to/your/media/files

# 5. Check the timestamped output directory for results!
```

**ğŸ‰ That's it!** The workflow system will handle the rest automatically.
